{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 28,\n",
    "            \"metadata\": {\n",
    "                \"execution\": {\n",
    "                    \"iopub.execute_input\": \"2021-12-09T15:42:30.890422Z\",\n",
    "                    \"iopub.status.busy\": \"2021-12-09T15:42:30.890036Z\",\n",
    "                    \"iopub.status.idle\": \"2021-12-09T15:42:37.774794Z\",\n",
    "                    \"shell.execute_reply\": \"2021-12-09T15:42:37.774062Z\",\n",
    "                    \"shell.execute_reply.started\": \"2021-12-09T15:42:30.890331Z\"\n",
    "                },\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"from keras.preprocessing.text import Tokenizer\\n\",\n",
    "                \"from keras.utils import pad_sequences\\n\",\n",
    "                \"from nltk.tokenize import word_tokenize\\n\",\n",
    "                \"from nltk.stem import WordNetLemmatizer\\n\",\n",
    "                \"from nltk.corpus import stopwords\\n\",\n",
    "                \"from tensorflow.python.keras.layers import *\\n\",\n",
    "                \"from tensorflow.python.keras.models import Model\\n\",\n",
    "                \"import numpy as np \\n\",\n",
    "                \"import pandas as pd \\n\",\n",
    "                \"import re\\n\",\n",
    "                \"import nltk\\n\",\n",
    "                \"from preprocess import *\\n\",\n",
    "                \"from models import *\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 29,\n",
    "            \"metadata\": {\n",
    "                \"execution\": {\n",
    "                    \"iopub.execute_input\": \"2021-12-09T15:42:52.454527Z\",\n",
    "                    \"iopub.status.busy\": \"2021-12-09T15:42:52.453714Z\",\n",
    "                    \"iopub.status.idle\": \"2021-12-09T15:43:01.326923Z\",\n",
    "                    \"shell.execute_reply\": \"2021-12-09T15:43:01.326227Z\",\n",
    "                    \"shell.execute_reply.started\": \"2021-12-09T15:42:52.454487Z\"\n",
    "                },\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"data\": {\n",
    "                        \"text/html\": [\n",
    "                            \"<div>\\n\",\n",
    "                            \"<style scoped>\\n\",\n",
    "                            \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "                            \"        vertical-align: middle;\\n\",\n",
    "                            \"    }\\n\",\n",
    "                            \"\\n\",\n",
    "                            \"    .dataframe tbody tr th {\\n\",\n",
    "                            \"        vertical-align: top;\\n\",\n",
    "                            \"    }\\n\",\n",
    "                            \"\\n\",\n",
    "                            \"    .dataframe thead th {\\n\",\n",
    "                            \"        text-align: right;\\n\",\n",
    "                            \"    }\\n\",\n",
    "                            \"</style>\\n\",\n",
    "                            \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "                            \"  <thead>\\n\",\n",
    "                            \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "                            \"      <th></th>\\n\",\n",
    "                            \"      <th>id</th>\\n\",\n",
    "                            \"      <th>qid1</th>\\n\",\n",
    "                            \"      <th>qid2</th>\\n\",\n",
    "                            \"      <th>question1</th>\\n\",\n",
    "                            \"      <th>question2</th>\\n\",\n",
    "                            \"      <th>is_duplicate</th>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"  </thead>\\n\",\n",
    "                            \"  <tbody>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>0</th>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"      <td>1</td>\\n\",\n",
    "                            \"      <td>2</td>\\n\",\n",
    "                            \"      <td>What is the step by step guide to invest in sh...</td>\\n\",\n",
    "                            \"      <td>What is the step by step guide to invest in sh...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>1</th>\\n\",\n",
    "                            \"      <td>1</td>\\n\",\n",
    "                            \"      <td>3</td>\\n\",\n",
    "                            \"      <td>4</td>\\n\",\n",
    "                            \"      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\\n\",\n",
    "                            \"      <td>What would happen if the Indian government sto...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>2</th>\\n\",\n",
    "                            \"      <td>2</td>\\n\",\n",
    "                            \"      <td>5</td>\\n\",\n",
    "                            \"      <td>6</td>\\n\",\n",
    "                            \"      <td>How can I increase the speed of my internet co...</td>\\n\",\n",
    "                            \"      <td>How can Internet speed be increased by hacking...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>3</th>\\n\",\n",
    "                            \"      <td>3</td>\\n\",\n",
    "                            \"      <td>7</td>\\n\",\n",
    "                            \"      <td>8</td>\\n\",\n",
    "                            \"      <td>Why am I mentally very lonely? How can I solve...</td>\\n\",\n",
    "                            \"      <td>Find the remainder when [math]23^{24}[/math] i...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>4</th>\\n\",\n",
    "                            \"      <td>4</td>\\n\",\n",
    "                            \"      <td>9</td>\\n\",\n",
    "                            \"      <td>10</td>\\n\",\n",
    "                            \"      <td>Which one dissolve in water quikly sugar, salt...</td>\\n\",\n",
    "                            \"      <td>Which fish would survive in salt water?</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"  </tbody>\\n\",\n",
    "                            \"</table>\\n\",\n",
    "                            \"</div>\"\n",
    "                        ],\n",
    "                        \"text/plain\": [\n",
    "                            \"   id  qid1  qid2                                          question1  \\\\\\n\",\n",
    "                            \"0   0     1     2  What is the step by step guide to invest in sh...   \\n\",\n",
    "                            \"1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \\n\",\n",
    "                            \"2   2     5     6  How can I increase the speed of my internet co...   \\n\",\n",
    "                            \"3   3     7     8  Why am I mentally very lonely? How can I solve...   \\n\",\n",
    "                            \"4   4     9    10  Which one dissolve in water quikly sugar, salt...   \\n\",\n",
    "                            \"\\n\",\n",
    "                            \"                                           question2  is_duplicate  \\n\",\n",
    "                            \"0  What is the step by step guide to invest in sh...             0  \\n\",\n",
    "                            \"1  What would happen if the Indian government sto...             0  \\n\",\n",
    "                            \"2  How can Internet speed be increased by hacking...             0  \\n\",\n",
    "                            \"3  Find the remainder when [math]23^{24}[/math] i...             0  \\n\",\n",
    "                            \"4            Which fish would survive in salt water?             0  \"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"execution_count\": 29,\n",
    "                    \"metadata\": {},\n",
    "                    \"output_type\": \"execute_result\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"df = pd.read_csv(\\\"questions.csv\\\")\\n\",\n",
    "                \"df.head()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 30,\n",
    "            \"metadata\": {\n",
    "                \"execution\": {\n",
    "                    \"iopub.execute_input\": \"2021-12-07T01:21:29.482516Z\",\n",
    "                    \"iopub.status.busy\": \"2021-12-07T01:21:29.482071Z\",\n",
    "                    \"iopub.status.idle\": \"2021-12-07T01:21:29.56485Z\",\n",
    "                    \"shell.execute_reply\": \"2021-12-07T01:21:29.564017Z\",\n",
    "                    \"shell.execute_reply.started\": \"2021-12-07T01:21:29.482481Z\"\n",
    "                },\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# question_1, question_2 = df['question1'].to_list(), df['question2'].to_list()\\n\",\n",
    "                \"# is_duplicate = df['is_duplicate'].to_list()\\n\",\n",
    "                \"# preprocess_neural(question_1, question_2, is_duplicate)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 31,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"data\": {\n",
    "                        \"text/plain\": [\n",
    "                            \"(50000, 6)\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"execution_count\": 31,\n",
    "                    \"metadata\": {},\n",
    "                    \"output_type\": \"execute_result\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"df = df.sample(n=50000, random_state=1)\\n\",\n",
    "                \"df.shape\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 32,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"q1_preprocessed, q2_preprocessed, is_duplicate = df['question1'].to_list(), df['question2'].to_list(), df['is_duplicate'].to_list()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"Acquired Test data\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 33,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"MAX_WORDS_VOCAB = 200000\\n\",\n",
    "                \"tokenizer = Tokenizer(num_words = MAX_WORDS_VOCAB, lower=False, split=\\\" \\\")\\n\",\n",
    "                \"tokenizer.fit_on_texts(list(df['question1'].values.astype(str))+list(df['question2'].values.astype(str)))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 34,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Number of words in vocabulary:  42981\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"print(\\\"Number of words in vocabulary: \\\", len(tokenizer.word_index))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 35,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"\\n\",\n",
    "                \"q1_sequence = tokenizer.texts_to_sequences(df['question1'].values.astype(str))\\n\",\n",
    "                \"q1_sequence = pad_sequences(q1_sequence, maxlen = 128)\\n\",\n",
    "                \"\\n\",\n",
    "                \"q2_sequence = tokenizer.texts_to_sequences(df['question2'].values.astype(str))\\n\",\n",
    "                \"q2_sequence = pad_sequences(q2_sequence, maxlen = 128)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 36,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"windex = tokenizer.word_index\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 37,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"embedding_index = {}\\n\",\n",
    "                \"with open('glove.6B.300d.txt','r') as f:\\n\",\n",
    "                \"    for line in f:\\n\",\n",
    "                \"        values = line.split()\\n\",\n",
    "                \"        word = values[0]\\n\",\n",
    "                \"        vectors = np.asarray(values[1:], 'float32')\\n\",\n",
    "                \"        embedding_index[word] = vectors\\n\",\n",
    "                \"    f.close()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 38,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"(42982, 300)\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"embedding_matrix = np.random.random((len(windex)+1, 300))\\n\",\n",
    "                \"\\n\",\n",
    "                \"for word, i in windex.items():\\n\",\n",
    "                \"    embedding_vector = embedding_index.get(word)\\n\",\n",
    "                \"    if embedding_vector is not None:\\n\",\n",
    "                \"        embedding_matrix[i] = embedding_vector\\n\",\n",
    "                \"\\n\",\n",
    "                \"print(embedding_matrix.shape)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 39,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"42982\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"print(len(windex)+1)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 40,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"#split the data into 70-20-10 train-validation-test with random state 42\\n\",\n",
    "                \"from sklearn.model_selection import train_test_split\\n\",\n",
    "                \"q1_train, q1_test, q2_train, q2_test, y_train, y_test = train_test_split(q1_sequence, q2_sequence, is_duplicate, test_size=0.1, random_state=42)\\n\",\n",
    "                \"q1_train, q1_val, q2_train, q2_val, y_train, y_val = train_test_split(q1_train, q2_train, y_train, test_size=0.2, random_state=42)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 41,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"import tensorflow as tf\\n\",\n",
    "                \"y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\\n\",\n",
    "                \"y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\\n\",\n",
    "                \"y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 42,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"(50000,)\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"is_duplicate = np.array(is_duplicate)\\n\",\n",
    "                \"print(is_duplicate.shape)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 43,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Train:  [0.6346111 0.3653889]\\n\",\n",
    "                        \"Validation:  [0.6388889 0.3611111]\\n\",\n",
    "                        \"Test:  [0.6274 0.3726]\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)\\n\",\n",
    "                \"print(\\\"Train: \\\", sum(y_train)/len(y_train))\\n\",\n",
    "                \"print(\\\"Validation: \\\", sum(y_val)/len(y_val))\\n\",\n",
    "                \"print(\\\"Test: \\\", sum(y_test)/len(y_test))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 45,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"model = BiLSTM(emb_mat = embedding_matrix, vocab_size = len(windex)+1, loss=\\\"categorical_crossentropy\\\")\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 46,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"model.train_model()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 47,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"model.train_model()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 48,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Model: \\\"model_4\\\"\\n\",\n",
    "                        \"__________________________________________________________________________________________________\\n\",\n",
    "                        \" Layer (type)                   Output Shape         Param #     Connected to                     \\n\",\n",
    "                        \"==================================================================================================\\n\",\n",
    "                        \" input_11 (InputLayer)          [(None, 128)]        0           []                               \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" input_12 (InputLayer)          [(None, 128)]        0           []                               \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" embedding_9 (Embedding)        (None, 128, 300)     12894600    ['input_11[0][0]']               \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" embedding_10 (Embedding)       (None, 128, 300)     12894600    ['input_12[0][0]']               \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.__operators__.add_4 (TFOpLa  (None, 128, 300)    0           ['embedding_9[0][0]',            \\n\",\n",
    "                        \" mbda)                                                            'embedding_10[0][0]']           \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.math.subtract_4 (TFOpLambda  (None, 128, 300)    0           ['embedding_9[0][0]',            \\n\",\n",
    "                        \" )                                                                'embedding_10[0][0]']           \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.math.multiply_4 (TFOpLambda  (None, 128, 300)    0           ['embedding_9[0][0]',            \\n\",\n",
    "                        \" )                                                                'embedding_10[0][0]']           \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" concatenate_4 (Concatenate)    (None, 128, 900)     0           ['tf.__operators__.add_4[0][0]', \\n\",\n",
    "                        \"                                                                  'tf.math.subtract_4[0][0]',     \\n\",\n",
    "                        \"                                                                  'tf.math.multiply_4[0][0]']     \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" bidirectional_4 (Bidirectional  (None, 128, 300)    1261200     ['concatenate_4[0][0]']          \\n\",\n",
    "                        \" )                                                                                                \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.math.reduce_mean_4 (TFOpLam  (None, 300)         0           ['bidirectional_4[0][0]']        \\n\",\n",
    "                        \" bda)                                                                                             \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" dense_4 (Dense)                (None, 2)            602         ['tf.math.reduce_mean_4[0][0]']  \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \"==================================================================================================\\n\",\n",
    "                        \"Total params: 27,051,002\\n\",\n",
    "                        \"Trainable params: 1,261,802\\n\",\n",
    "                        \"Non-trainable params: 25,789,200\\n\",\n",
    "                        \"__________________________________________________________________________________________________\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"model.get_model_summary()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 49,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"(9000, 128)\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"print(q1_val.shape)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 50,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Epoch 1/4\\n\",\n",
    "                        \"4500/4500 [==============================] - 1728s 383ms/step - loss: 0.7613 - accuracy: 0.6542 - val_loss: 0.6347 - val_accuracy: 0.6764\\n\",\n",
    "                        \"Epoch 2/4\\n\",\n",
    "                        \"4500/4500 [==============================] - 1746s 388ms/step - loss: 0.5947 - accuracy: 0.7354 - val_loss: 0.5314 - val_accuracy: 0.7526\\n\",\n",
    "                        \"Epoch 3/4\\n\",\n",
    "                        \"4500/4500 [==============================] - 1754s 390ms/step - loss: 0.5743 - accuracy: 0.7518 - val_loss: 0.5419 - val_accuracy: 0.7424\\n\",\n",
    "                        \"Epoch 4/4\\n\",\n",
    "                        \"4500/4500 [==============================] - 1762s 392ms/step - loss: 0.5501 - accuracy: 0.7729 - val_loss: 0.5112 - val_accuracy: 0.7712\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"model.model.fit([q1_train, q2_train], y_train, epochs = 4, validation_data = ([q1_val, q2_val], y_val), batch_size = 8, validation_batch_size=4, verbose = 1)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": null,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Accuracy:  0.790922939954496\\n\",\n",
    "                        \"F1 Score:  0.7637004912961728\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"y_pred = model.predict([q1_test, q2_test])\\n\",\n",
    "                \"y_pred1d, y_actual1d = [], []\\n\",\n",
    "                \"for i in range(len(y_test)):\\n\",\n",
    "                \"    if(y_test[i][0] == 1):\\n\",\n",
    "                \"        y_actual1d.append(0)\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        y_actual1d.append(1)\\n\",\n",
    "                \"\\n\",\n",
    "                \"for i in range(len(y_pred)):\\n\",\n",
    "                \"    if(y_pred[i][0] > y_pred[i][1]):\\n\",\n",
    "                \"        y_pred1d.append(0)\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        y_pred1d.append(1)\\n\",\n",
    "                \"\\n\",\n",
    "                \"from sklearn.metrics import accuracy_score, f1_score\\n\",\n",
    "                \"print(\\\"Accuracy: \\\", accuracy_score(y_actual1d, y_pred1d))\\n\",\n",
    "                \"print(\\\"F1 Score: \\\", f1_score(y_actual1d, y_pred1d))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": null,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": []\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3.10.4 64-bit\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\"\n",
    "        },\n",
    "        \"language_info\": {\n",
    "            \"codemirror_mode\": {\n",
    "                \"name\": \"ipython\",\n",
    "                \"version\": 3\n",
    "            },\n",
    "            \"file_extension\": \".py\",\n",
    "            \"mimetype\": \"text/x-python\",\n",
    "            \"name\": \"python\",\n",
    "            \"nbconvert_exporter\": \"python\",\n",
    "            \"pygments_lexer\": \"ipython3\",\n",
    "            \"version\": \"3.10.4\"\n",
    "        },\n",
    "        \"vscode\": {\n",
    "            \"interpreter\": {\n",
    "                \"hash\": \"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
