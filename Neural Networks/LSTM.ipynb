{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 1,\n",
    "            \"metadata\": {\n",
    "                \"execution\": {\n",
    "                    \"iopub.execute_input\": \"2021-12-09T15:42:30.890422Z\",\n",
    "                    \"iopub.status.busy\": \"2021-12-09T15:42:30.890036Z\",\n",
    "                    \"iopub.status.idle\": \"2021-12-09T15:42:37.774794Z\",\n",
    "                    \"shell.execute_reply\": \"2021-12-09T15:42:37.774062Z\",\n",
    "                    \"shell.execute_reply.started\": \"2021-12-09T15:42:30.890331Z\"\n",
    "                },\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stderr\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"2022-12-02 14:17:50.032968: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\\n\",\n",
    "                        \"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n\",\n",
    "                        \"2022-12-02 14:17:51.562438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\\n\",\n",
    "                        \"2022-12-02 14:17:51.562735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\\n\",\n",
    "                        \"2022-12-02 14:17:51.562746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"from keras.preprocessing.text import Tokenizer\\n\",\n",
    "                \"from keras.utils import pad_sequences\\n\",\n",
    "                \"from nltk.tokenize import word_tokenize\\n\",\n",
    "                \"from nltk.stem import WordNetLemmatizer\\n\",\n",
    "                \"from nltk.corpus import stopwords\\n\",\n",
    "                \"from tensorflow.python.keras.layers import *\\n\",\n",
    "                \"from tensorflow.python.keras.models import Model\\n\",\n",
    "                \"import numpy as np \\n\",\n",
    "                \"import pandas as pd \\n\",\n",
    "                \"import re\\n\",\n",
    "                \"import nltk\\n\",\n",
    "                \"from preprocess import *\\n\",\n",
    "                \"from models import *\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 2,\n",
    "            \"metadata\": {\n",
    "                \"execution\": {\n",
    "                    \"iopub.execute_input\": \"2021-12-09T15:42:52.454527Z\",\n",
    "                    \"iopub.status.busy\": \"2021-12-09T15:42:52.453714Z\",\n",
    "                    \"iopub.status.idle\": \"2021-12-09T15:43:01.326923Z\",\n",
    "                    \"shell.execute_reply\": \"2021-12-09T15:43:01.326227Z\",\n",
    "                    \"shell.execute_reply.started\": \"2021-12-09T15:42:52.454487Z\"\n",
    "                },\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"data\": {\n",
    "                        \"text/html\": [\n",
    "                            \"<div>\\n\",\n",
    "                            \"<style scoped>\\n\",\n",
    "                            \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "                            \"        vertical-align: middle;\\n\",\n",
    "                            \"    }\\n\",\n",
    "                            \"\\n\",\n",
    "                            \"    .dataframe tbody tr th {\\n\",\n",
    "                            \"        vertical-align: top;\\n\",\n",
    "                            \"    }\\n\",\n",
    "                            \"\\n\",\n",
    "                            \"    .dataframe thead th {\\n\",\n",
    "                            \"        text-align: right;\\n\",\n",
    "                            \"    }\\n\",\n",
    "                            \"</style>\\n\",\n",
    "                            \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "                            \"  <thead>\\n\",\n",
    "                            \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "                            \"      <th></th>\\n\",\n",
    "                            \"      <th>id</th>\\n\",\n",
    "                            \"      <th>qid1</th>\\n\",\n",
    "                            \"      <th>qid2</th>\\n\",\n",
    "                            \"      <th>question1</th>\\n\",\n",
    "                            \"      <th>question2</th>\\n\",\n",
    "                            \"      <th>is_duplicate</th>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"  </thead>\\n\",\n",
    "                            \"  <tbody>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>0</th>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"      <td>1</td>\\n\",\n",
    "                            \"      <td>2</td>\\n\",\n",
    "                            \"      <td>What is the step by step guide to invest in sh...</td>\\n\",\n",
    "                            \"      <td>What is the step by step guide to invest in sh...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>1</th>\\n\",\n",
    "                            \"      <td>1</td>\\n\",\n",
    "                            \"      <td>3</td>\\n\",\n",
    "                            \"      <td>4</td>\\n\",\n",
    "                            \"      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\\n\",\n",
    "                            \"      <td>What would happen if the Indian government sto...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>2</th>\\n\",\n",
    "                            \"      <td>2</td>\\n\",\n",
    "                            \"      <td>5</td>\\n\",\n",
    "                            \"      <td>6</td>\\n\",\n",
    "                            \"      <td>How can I increase the speed of my internet co...</td>\\n\",\n",
    "                            \"      <td>How can Internet speed be increased by hacking...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>3</th>\\n\",\n",
    "                            \"      <td>3</td>\\n\",\n",
    "                            \"      <td>7</td>\\n\",\n",
    "                            \"      <td>8</td>\\n\",\n",
    "                            \"      <td>Why am I mentally very lonely? How can I solve...</td>\\n\",\n",
    "                            \"      <td>Find the remainder when [math]23^{24}[/math] i...</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"    <tr>\\n\",\n",
    "                            \"      <th>4</th>\\n\",\n",
    "                            \"      <td>4</td>\\n\",\n",
    "                            \"      <td>9</td>\\n\",\n",
    "                            \"      <td>10</td>\\n\",\n",
    "                            \"      <td>Which one dissolve in water quikly sugar, salt...</td>\\n\",\n",
    "                            \"      <td>Which fish would survive in salt water?</td>\\n\",\n",
    "                            \"      <td>0</td>\\n\",\n",
    "                            \"    </tr>\\n\",\n",
    "                            \"  </tbody>\\n\",\n",
    "                            \"</table>\\n\",\n",
    "                            \"</div>\"\n",
    "                        ],\n",
    "                        \"text/plain\": [\n",
    "                            \"   id  qid1  qid2                                          question1  \\\\\\n\",\n",
    "                            \"0   0     1     2  What is the step by step guide to invest in sh...   \\n\",\n",
    "                            \"1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \\n\",\n",
    "                            \"2   2     5     6  How can I increase the speed of my internet co...   \\n\",\n",
    "                            \"3   3     7     8  Why am I mentally very lonely? How can I solve...   \\n\",\n",
    "                            \"4   4     9    10  Which one dissolve in water quikly sugar, salt...   \\n\",\n",
    "                            \"\\n\",\n",
    "                            \"                                           question2  is_duplicate  \\n\",\n",
    "                            \"0  What is the step by step guide to invest in sh...             0  \\n\",\n",
    "                            \"1  What would happen if the Indian government sto...             0  \\n\",\n",
    "                            \"2  How can Internet speed be increased by hacking...             0  \\n\",\n",
    "                            \"3  Find the remainder when [math]23^{24}[/math] i...             0  \\n\",\n",
    "                            \"4            Which fish would survive in salt water?             0  \"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"execution_count\": 2,\n",
    "                    \"metadata\": {},\n",
    "                    \"output_type\": \"execute_result\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"df = pd.read_csv(\\\"questions.csv\\\")\\n\",\n",
    "                \"df.head()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 3,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"data\": {\n",
    "                        \"text/plain\": [\n",
    "                            \"(404351, 6)\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"execution_count\": 3,\n",
    "                    \"metadata\": {},\n",
    "                    \"output_type\": \"execute_result\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"df.shape\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 4,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"data\": {\n",
    "                        \"text/plain\": [\n",
    "                            \"(100000, 6)\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"execution_count\": 4,\n",
    "                    \"metadata\": {},\n",
    "                    \"output_type\": \"execute_result\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"#pick a sample of 5000 distinct random rows\\n\",\n",
    "                \"df = df.sample(n=100000, random_state=1)\\n\",\n",
    "                \"df.shape\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 5,\n",
    "            \"metadata\": {\n",
    "                \"execution\": {\n",
    "                    \"iopub.execute_input\": \"2021-12-07T01:21:29.482516Z\",\n",
    "                    \"iopub.status.busy\": \"2021-12-07T01:21:29.482071Z\",\n",
    "                    \"iopub.status.idle\": \"2021-12-07T01:21:29.56485Z\",\n",
    "                    \"shell.execute_reply\": \"2021-12-07T01:21:29.564017Z\",\n",
    "                    \"shell.execute_reply.started\": \"2021-12-07T01:21:29.482481Z\"\n",
    "                },\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# question_1, question_2 = df['question1'].to_list(), df['question2'].to_list()\\n\",\n",
    "                \"# is_duplicate = df['is_duplicate'].to_list()\\n\",\n",
    "                \"# preprocess_neural(question_1, question_2, is_duplicate)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 6,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"q1_inp, q2_inp, is_duplicate = df['question1'].to_list(), df['question2'].to_list(), df['is_duplicate'].to_list()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"Acquired Test data\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 7,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"MAX_WORDS_VOCAB = 200000\\n\",\n",
    "                \"tokenizer = Tokenizer(num_words = MAX_WORDS_VOCAB, lower=False, split=\\\" \\\")\\n\",\n",
    "                \"tokenizer.fit_on_texts(list(df['question1'].values.astype(str))+list(df['question2'].values.astype(str)))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 8,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Number of words in vocabulary:  60949\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"print(\\\"Number of words in vocabulary: \\\", len(tokenizer.word_index))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 9,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"\\n\",\n",
    "                \"q1_sequence = tokenizer.texts_to_sequences(df['question1'].values.astype(str))\\n\",\n",
    "                \"q1_sequence = pad_sequences(q1_sequence, maxlen = 128)\\n\",\n",
    "                \"\\n\",\n",
    "                \"q2_sequence = tokenizer.texts_to_sequences(df['question2'].values.astype(str))\\n\",\n",
    "                \"q2_sequence = pad_sequences(q2_sequence, maxlen = 128)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 10,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"windex = tokenizer.word_index\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 11,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"embedding_index = {}\\n\",\n",
    "                \"with open('glove.6B.300d.txt','r') as f:\\n\",\n",
    "                \"    for line in f:\\n\",\n",
    "                \"        values = line.split()\\n\",\n",
    "                \"        word = values[0]\\n\",\n",
    "                \"        vectors = np.asarray(values[1:], 'float32')\\n\",\n",
    "                \"        embedding_index[word] = vectors\\n\",\n",
    "                \"    f.close()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 12,\n",
    "            \"metadata\": {\n",
    "                \"trusted\": true\n",
    "            },\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"(60950, 300)\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"embedding_matrix = np.random.random((len(windex)+1, 300))\\n\",\n",
    "                \"\\n\",\n",
    "                \"for word, i in windex.items():\\n\",\n",
    "                \"    embedding_vector = embedding_index.get(word)\\n\",\n",
    "                \"    if embedding_vector is not None:\\n\",\n",
    "                \"        embedding_matrix[i] = embedding_vector\\n\",\n",
    "                \"\\n\",\n",
    "                \"print(embedding_matrix.shape)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 13,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"60950\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"print(len(windex)+1)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 14,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"#split the data into 70-20-10 train-validation-test with random state 42\\n\",\n",
    "                \"from sklearn.model_selection import train_test_split\\n\",\n",
    "                \"q1_train, q1_test, q2_train, q2_test, y_train, y_test = train_test_split(q1_sequence, q2_sequence, is_duplicate, test_size=0.1, random_state=42)\\n\",\n",
    "                \"q1_train, q1_val, q2_train, q2_val, y_train, y_val = train_test_split(q1_train, q2_train, y_train, test_size=0.2, random_state=42)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 15,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"import tensorflow as tf\\n\",\n",
    "                \"y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\\n\",\n",
    "                \"y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\\n\",\n",
    "                \"y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 16,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"(100000,)\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"is_duplicate = np.array(is_duplicate)\\n\",\n",
    "                \"print(is_duplicate.shape)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 17,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Train:  [0.63294444 0.36705556]\\n\",\n",
    "                        \"Validation:  [0.6358333  0.36416668]\\n\",\n",
    "                        \"Test:  [0.6291 0.3709]\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"#print the ratio of positive and negative samples in train, validation and test\\n\",\n",
    "                \"y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)\\n\",\n",
    "                \"print(\\\"Train: \\\", sum(y_train)/len(y_train))\\n\",\n",
    "                \"print(\\\"Validation: \\\", sum(y_val)/len(y_val))\\n\",\n",
    "                \"print(\\\"Test: \\\", sum(y_test)/len(y_test))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 19,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stderr\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"2022-12-02 14:18:17.626672: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\\n\",\n",
    "                        \"2022-12-02 14:18:17.626735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os): /proc/driver/nvidia/version does not exist\\n\",\n",
    "                        \"2022-12-02 14:18:17.627957: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\\n\",\n",
    "                        \"To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"model = LsTM(emb_mat = embedding_matrix, vocab_size = len(windex)+1)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 20,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"model.train_model()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 21,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"model = LsTM(embedding_matrix, len(windex) + 1, loss=\\\"categorical_crossentropy\\\")\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 22,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"model.train_model()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 23,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Model: \\\"model_1\\\"\\n\",\n",
    "                        \"__________________________________________________________________________________________________\\n\",\n",
    "                        \" Layer (type)                   Output Shape         Param #     Connected to                     \\n\",\n",
    "                        \"==================================================================================================\\n\",\n",
    "                        \" input_3 (InputLayer)           [(None, 128)]        0           []                               \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" input_4 (InputLayer)           [(None, 128)]        0           []                               \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" embedding_2 (Embedding)        (None, 128, 300)     18285000    ['input_3[0][0]']                \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" embedding_3 (Embedding)        (None, 128, 300)     18285000    ['input_4[0][0]']                \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.__operators__.add_1 (TFOpLa  (None, 128, 300)    0           ['embedding_2[0][0]',            \\n\",\n",
    "                        \" mbda)                                                            'embedding_3[0][0]']            \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.math.subtract_1 (TFOpLambda  (None, 128, 300)    0           ['embedding_2[0][0]',            \\n\",\n",
    "                        \" )                                                                'embedding_3[0][0]']            \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" tf.math.multiply_1 (TFOpLambda  (None, 128, 300)    0           ['embedding_2[0][0]',            \\n\",\n",
    "                        \" )                                                                'embedding_3[0][0]']            \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" concatenate_1 (Concatenate)    (None, 128, 900)     0           ['tf.__operators__.add_1[0][0]', \\n\",\n",
    "                        \"                                                                  'tf.math.subtract_1[0][0]',     \\n\",\n",
    "                        \"                                                                  'tf.math.multiply_1[0][0]']     \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" lstm_1 (LSTM)                  [(None, 150),        630600      ['concatenate_1[0][0]']          \\n\",\n",
    "                        \"                                 (None, 150),                                                     \\n\",\n",
    "                        \"                                 (None, 150)]                                                     \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \" dense_1 (Dense)                (None, 2)            302         ['lstm_1[0][2]']                 \\n\",\n",
    "                        \"                                                                                                  \\n\",\n",
    "                        \"==================================================================================================\\n\",\n",
    "                        \"Total params: 37,200,902\\n\",\n",
    "                        \"Trainable params: 630,902\\n\",\n",
    "                        \"Non-trainable params: 36,570,000\\n\",\n",
    "                        \"__________________________________________________________________________________________________\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"model.get_model_summary()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 24,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"(18000, 128)\\n\"\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"print(q1_val.shape)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 25,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"Epoch 1/4\\n\",\n",
    "                        \"9000/9000 [==============================] - 1342s 149ms/step - loss: 0.5511 - accuracy: 0.7175 - val_loss: 0.5226 - val_accuracy: 0.7364\\n\",\n",
    "                        \"Epoch 2/4\\n\",\n",
    "                        \"9000/9000 [==============================] - 1363s 151ms/step - loss: 0.4874 - accuracy: 0.7626 - val_loss: 0.5049 - val_accuracy: 0.7547\\n\",\n",
    "                        \"Epoch 3/4\\n\",\n",
    "                        \"9000/9000 [==============================] - 1333s 148ms/step - loss: 0.4301 - accuracy: 0.7970 - val_loss: 0.4883 - val_accuracy: 0.7714\\n\",\n",
    "                        \"Epoch 4/4\\n\",\n",
    "                        \"9000/9000 [==============================] - 1315s 146ms/step - loss: 0.3721 - accuracy: 0.8288 - val_loss: 0.4709 - val_accuracy: 0.7901\\n\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"data\": {\n",
    "                        \"text/plain\": [\n",
    "                            \"<keras.callbacks.History at 0x7f1f29bde260>\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"execution_count\": 25,\n",
    "                    \"metadata\": {},\n",
    "                    \"output_type\": \"execute_result\"\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"model.model.fit([q1_train, q2_train], y_train, epochs = 4, validation_data = ([q1_val, q2_val], y_val), batch_size = 8, validation_batch_size=4, verbose = 1)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 26,\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"stdout\",\n",
    "                    \"output_type\": \"stream\",\n",
    "                    \"text\": [\n",
    "                        \"313/313 [==============================] - 25s 71ms/step\\n\",\n",
    "                        \"Accuracy:  0.784100015\\n\",\n",
    "                        \"F1 Score:  0.7357100716392751\\n\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"ename\": \"\",\n",
    "                    \"evalue\": \"\",\n",
    "                    \"output_type\": \"error\",\n",
    "                    \"traceback\": []\n",
    "                }\n",
    "            ],\n",
    "            \"source\": [\n",
    "                \"y_pred = model.predict([q1_test, q2_test])\\n\",\n",
    "                \"y_pred1d, y_actual1d = [], []\\n\",\n",
    "                \"for i in range(len(y_test)):\\n\",\n",
    "                \"    if(y_test[i][0] == 1):\\n\",\n",
    "                \"        y_actual1d.append(0)\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        y_actual1d.append(1)\\n\",\n",
    "                \"\\n\",\n",
    "                \"for i in range(len(y_pred)):\\n\",\n",
    "                \"    if(y_pred[i][0] > y_pred[i][1]):\\n\",\n",
    "                \"        y_pred1d.append(0)\\n\",\n",
    "                \"    else:\\n\",\n",
    "                \"        y_pred1d.append(1)\\n\",\n",
    "                \"\\n\",\n",
    "                \"from sklearn.metrics import accuracy_score, f1_score\\n\",\n",
    "                \"print(\\\"Accuracy: \\\", accuracy_score(y_actual1d, y_pred1d))\\n\",\n",
    "                \"print(\\\"F1 Score: \\\", f1_score(y_actual1d, y_pred1d))\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3.10.4 64-bit\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\"\n",
    "        },\n",
    "        \"language_info\": {\n",
    "            \"codemirror_mode\": {\n",
    "                \"name\": \"ipython\",\n",
    "                \"version\": 3\n",
    "            },\n",
    "            \"file_extension\": \".py\",\n",
    "            \"mimetype\": \"text/x-python\",\n",
    "            \"name\": \"python\",\n",
    "            \"nbconvert_exporter\": \"python\",\n",
    "            \"pygments_lexer\": \"ipython3\",\n",
    "            \"version\": \"3.10.4\"\n",
    "        },\n",
    "        \"vscode\": {\n",
    "            \"interpreter\": {\n",
    "                \"hash\": \"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
